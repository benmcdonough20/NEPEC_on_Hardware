{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the PEC procedure\n",
    "I discovered that there were a few issues in my code, so this notebook runs some tests and compares them to theoretical results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qiskit.providers.aer.noise import kraus_error, NoiseModel\n",
    "from qiskit.quantum_info import Kraus, Pauli\n",
    "from qiskit import Aer, QuantumCircuit, execute\n",
    "from numpy.random import rand, randint, choice\n",
    "from decimal import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying error model\n",
    "\n",
    "For simplicity, I am using one $\\lambda$ for all of the parameters, and consequently one $\\omega$.\n",
    "\n",
    "I computed the expectation value $\\operatorname{Tr}[Z \\tilde{\\mathcal{X}}(\\rho)]$, where\n",
    "$$\n",
    "\\rho = |0\\rangle\\langle 0| \\ \\ \\ \\text{and} \\ \\ \\ \\widetilde{\\mathcal{X}}(\\rho) = \\Lambda \\circ \\mathcal{X}(\\rho)\n",
    "$$\n",
    "Let $\\hat{P} = P^T \\otimes P$ be the superoperator representing of $P$. Importantly, \n",
    "$$\n",
    "\\hat X \\hat X = \\hat Y \\hat Y = \\hat Z \\hat Z = \\hat I\\\\\n",
    "\\hat X \\hat Y = \\hat Y \\hat X = \\hat Z\\\\\n",
    "\\hat Y \\hat Z = \\hat Z \\hat Y = \\hat X\\\\\n",
    "\\hat Z \\hat X = \\hat X \\hat Z = \\hat Y\n",
    "$$\n",
    "Due to the fact that all Paulis either commute or anticommute. Using this the noise can be expanded:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Lambda &= (\\omega \\hat I+(1-\\omega)\\hat X)(\\omega \\hat I+(1-\\omega)\\hat Y)(\\omega \\hat I+(1-\\omega)\\hat Z)\\\\\n",
    "&= \\omega^3\\hat I+\\omega^2(1-\\omega)\\hat Y+\\omega^2(1-\\omega)\\hat X+\\omega^2(1-\\omega)\\hat Z+\\omega(1-\\omega)^2\\hat X+\\omega(1-\\omega)^2\\hat Y + (1-\\omega)^3 \\hat I\\\\\n",
    "&= [\\omega^3+(1-\\omega)^3]\\hat I + \\omega(1-\\omega)(\\hat X+\\hat Y + \\hat Z)\n",
    "\\end{align*}\n",
    "$$\n",
    "Thus this is reduced to depolarizing noise with $p = \\omega(1-\\omega)$. Composing $X$ into this operator, the noisy gate can be written as a sum of Pauli operators:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Lambda \\circ \\hat X &=\\omega^3+(1-\\omega)^3]\\hat I + \\omega(1-\\omega)(\\hat X+\\hat Y + \\hat Z) \\circ \\hat X\\\\\n",
    "&=\\omega^3+(1-\\omega)^3]\\hat X + \\omega(1-\\omega)(\\hat I+\\hat Z + \\hat Y)\n",
    "\\end{align*}\n",
    "$$\n",
    "With this expansion, the expectation value under noise can be estimated:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\operatorname{Tr}[Z\\tilde{\\mathcal{X}}(\\rho)] &= [\\omega^3+(1-\\omega)^3]\\operatorname{Tr}[Z\\mathcal{X}(\\rho)] + \\omega(1-\\omega)\\operatorname{Tr}[Z\\rho]+ \\omega(1-\\omega)\\operatorname{Tr}[Z\\mathcal{Z}(\\rho)]  +\\omega(1-\\omega)\\operatorname{Tr}[Z\\mathcal{Y}(\\rho)] \\\\\n",
    "&= [\\omega^3+(1-\\omega)^3](-1) + \\omega(1-\\omega)(1)+ \\omega(1-\\omega)(1)  +\\omega(1-\\omega)(-1)\\\\\n",
    "&= \\omega(1-\\omega)-\\omega^3-(1-\\omega)^3\\\\\n",
    "\\operatorname{Tr}[Z\\tilde{\\mathcal{I}}(\\rho)] &= [\\omega^3+(1-\\omega)^3](1) + \\omega(1-\\omega)(-1)+ \\omega(1-\\omega)(-1)  +\\omega(1-\\omega)(1)\\\\\n",
    "&= \\omega^3+(1-\\omega)^3-\\omega(1-\\omega)\\\\\n",
    "\\operatorname{Tr}[Z\\tilde{\\mathcal{Z}}(\\rho)] &=\\operatorname{Tr}[Z\\tilde{\\mathcal{I}}(\\rho)]\\\\\n",
    "\\operatorname{Tr}[Z\\tilde{\\mathcal{Y}}(\\rho)] &= \\operatorname{Tr}[Z\\tilde{\\mathcal{X}}(\\rho)]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbda = .05\n",
    "w = .5*(1+np.exp(-2*lmbda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the error model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "kraus_ops = Kraus(np.identity(2))\n",
    "for p in ['X','Y','Z']:\n",
    "    op = Kraus([Pauli(p).to_matrix()*np.sqrt(1-w),np.sqrt(w)*np.identity(2)]);\n",
    "    kraus_ops = kraus_ops.compose(op);\n",
    "\n",
    "kraus_error_channel = kraus_error(kraus_ops.data)\n",
    "kraus_noise_model = NoiseModel()\n",
    "kraus_noise_model.add_all_qubit_quantum_error(kraus_error_channel, ['id', 'rx', 'ry', 'rz'])\n",
    "kraus_basis_gates = kraus_noise_model.basis_gates\n",
    "\n",
    "def expectation(counts):\n",
    "    if not '0' in list(counts.keys()):\n",
    "        return -1\n",
    "    if not '1' in list(counts.keys()):\n",
    "        return 1\n",
    "    return (counts['0']-counts['1'])/(counts['0']+counts['1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had some trouble with the noise model not affecting all of the gates due to the basis gates I chose. This next cell tests to make sure that each gate carries the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted I:  0.819\n",
      "Simulated I:  0.817\n",
      "Predicted X:  -0.819\n",
      "Simulated X:  -0.813\n",
      "Predicted Y:  -0.819\n",
      "Simulated Y:  -0.820\n",
      "Predicted Z:  0.819\n",
      "Simulated Z:  0.815\n"
     ]
    }
   ],
   "source": [
    "backend = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "circ= QuantumCircuit(1,1)\n",
    "circ.barrier()\n",
    "circ.id(0)\n",
    "circ.barrier()\n",
    "circ.measure(0,0)\n",
    "job = execute(circ, backend, noise_model = kraus_noise_model, basis_gates = kraus_basis_gates, shots = 10000, optimization_level=0)\n",
    "expec_i = expectation(job.result().get_counts())\n",
    "print(\"Predicted I: \", \"%.3f\"%(w**3+(1-w)**3-w*(1-w)))\n",
    "print(\"Simulated I: \", \"%.3f\"%expec_i)\n",
    "\n",
    "circ= QuantumCircuit(1,1)\n",
    "circ.barrier()\n",
    "circ.x(0)\n",
    "circ.barrier()\n",
    "circ.measure(0,0)\n",
    "job = execute(circ, backend, noise_model = kraus_noise_model, basis_gates = kraus_basis_gates, shots = 10000, optimization_level=0)\n",
    "expec_x = expectation(job.result().get_counts())\n",
    "print(\"Predicted X: \", \"%.3f\"%(w*(1-w)-w**3-(1-w)**3))\n",
    "print(\"Simulated X: \", \"%.3f\"%expec_x)\n",
    "\n",
    "circ= QuantumCircuit(1,1)\n",
    "circ.barrier()\n",
    "circ.y(0)\n",
    "circ.barrier()\n",
    "circ.measure(0,0)\n",
    "job = execute(circ, backend, noise_model = kraus_noise_model, basis_gates = kraus_basis_gates, shots = 10000, optimization_level=0)\n",
    "expec_y = expectation(job.result().get_counts())\n",
    "print(\"Predicted Y: \", \"%.3f\"%(w*(1-w)-w**3-(1-w)**3))\n",
    "print(\"Simulated Y: \", \"%.3f\"%expec_y)\n",
    "\n",
    "circ= QuantumCircuit(1,1)\n",
    "circ.barrier()\n",
    "circ.z(0)\n",
    "circ.barrier()\n",
    "circ.measure(0,0)\n",
    "job = execute(circ, backend, noise_model = kraus_noise_model, basis_gates = kraus_basis_gates, shots = 10000, optimization_level=0)\n",
    "expec_z = expectation(job.result().get_counts())\n",
    "print(\"Predicted Z: \", \"%.3f\"%(w**3+(1-w)**3-w*(1-w)))\n",
    "print(\"Simulated Z: \", \"%.3f\"%expec_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing PEC numerically\n",
    "\n",
    "I wanted to check to see if I was understanding the PEC algorithm. My interpretation is that we want to find a gate $\\mathcal{G} = \\sum_i p_i \\mathcal{P}_i$ such that $\\mathcal{X} = \\Lambda \\circ \\mathcal{G}$. Having access to the inverse of the noise, this gives\n",
    "$$\n",
    "\\mathcal{G} = \\Lambda^{-1} \\circ \\mathcal{X}\n",
    "$$\n",
    "With overhead $\\gamma = \\frac{1}{(2\\omega-1)^3}$, the inverse of the noise can be written in terms of ideal gates as\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Lambda^{-1} &= \\gamma(\\omega \\hat I - (1-\\omega) \\hat X)(\\omega \\hat I-(1-\\omega)\\hat Y)(\\omega \\hat I-(1-\\omega)\\hat Z) \\\\\n",
    "&= \\gamma(\\omega^3 \\hat I - (1-\\omega)\\omega^2 \\hat Y - (1-\\omega)\\omega^2 \\hat X + (1-\\omega)^2 \\omega \\hat Z + (1-\\omega)^2\\omega \\hat X + (1-\\omega)^2\\omega \\hat Y - (1-\\omega)^3 \\hat I)\\\\\n",
    "&= \\gamma((\\omega^3-(1-\\omega)^3)\\hat I + (1-\\omega)^2\\omega-(1-\\omega)\\omega^2)(\\hat X + \\hat Y + \\hat Z))\\\\\n",
    "&= \\gamma((\\omega^3-(1-\\omega)^3)\\hat I + \\omega(1-\\omega)(1-2\\omega)(\\hat X + \\hat Y + \\hat Z))\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "Composing $\\hat X$ into this operator gives\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Lambda^{-1} \\circ \\hat{X} &= \\gamma((\\omega^3-(1-\\omega)^3)\\hat X + \\omega(1-\\omega)(1-2\\omega)(\\hat I + \\hat Z + \\hat Y))\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "This is the operator $\\mathcal{G}$, and in applying $\\mathcal{G}$ the operator that actually gets applied is the noisy version, \n",
    "$$\n",
    "\\Lambda \\circ \\mathcal{G} = (\\omega^3-(1-\\omega)^3)\\mathcal{X} + \\omega(1-\\omega)(1-2\\omega)(\\mathcal{I} + \\mathcal{Z} + \\mathcal{Y}) = \\mathcal{X}\n",
    "$$\n",
    "\n",
    "Using this representation, the error-corrected expectation value is expressable in terms of the noisy expectation values,\n",
    "$$\n",
    "\\operatorname{Tr}[Z\\mathcal{X}(\\rho)] = \\gamma((\\omega^3-(1-\\omega)^3)\\operatorname{Tr}[Z\\mathcal{\\tilde X}(\\rho)] + (1-\\omega)\\omega(1-2\\omega)(\\operatorname{Tr}[Z\\mathcal{\\tilde I}(\\rho)]+ \\operatorname{Tr}[Z\\mathcal{\\tilde Z}(\\rho)] + \\operatorname{Tr}[Z\\mathcal{\\tilde Y}(\\rho)]))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below shows that in principle, if the probabilities of each outcome are known, then the PEC scheme works. However the variance is large. I saw values $\\pm .2$ for 10000 shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mitigation using calculated probabiliities and estimations:  -0.9999999999999998\n",
      "Mitigation using calculated probabilities and estimated expectations:  -0.9933768270730903\n"
     ]
    }
   ],
   "source": [
    "overhead = 1/(2*w-1)**3\n",
    "ideal_mitigated = -1*(w**3+(1-w)**3-w*(1-w))*(w**3-(1-w)**3)+w*(1-w)*(1-2*w)*(w**3+(1-w)**3-w*(1-w))\n",
    "mitigated = expec_x*(w**3-(1-w)**3)+w*(1-w)*(1-2*w)*(expec_i+expec_z+expec_x)\n",
    "print(\"Mitigation using calculated probabiliities and estimations: \", ideal_mitigated*float(overhead))\n",
    "print(\"Mitigation using calculated probabilities and estimated expectations: \", mitigated*float(overhead))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from the inverse\n",
    "\n",
    "I also wanted to test whether the procedure I was using to sample from the inverse distribution produced the correct probability distribution. Since this is only the case of a single gate, the circuits can be sorted into $I, X, Y, Z$ applications. After taking a large number of samples, the probability of coming up with each of these circuits is compared to the theoretically predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = .5*(1+np.exp(-2*lmbda))\n",
    "m = 1-w\n",
    "\n",
    "probs = [\n",
    "    w*(1-w)*(1-2*w),\n",
    "    w**3-(1-w)**3,\n",
    "    w*(1-w)*(1-2*w),\n",
    "    w*(1-w)*(1-2*w),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `probs` array is not a quasiprobability distribution. The fact that the probabilities are not normalized reflects the fact that $|a-b| \\neq |a|+|b|$, because some of the pauli operators are sums of both negative and positive terms. Sampling the distribution without taking the negative coefficients into account should give `np.abs(probs)/np.sum(np.abs(probs)`, and by adjusting for the negative coefficients, it should recover `probs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled distribution:  [0.056, 0.852, 0.051, 0.041]\n",
      "ideal distibition : [0.04155132 0.87534603 0.04155132 0.04155132]\n",
      "simulated coefficients : [-0.05, 0.852, -0.045, -0.041]\n",
      "ideal coefficients : [-0.041004799338560445, 0.863832618697399, -0.041004799338560445, -0.041004799338560445]\n"
     ]
    }
   ],
   "source": [
    "samples = 1000\n",
    "circuits_adjusted = {'I':0, 'X':0, 'Y':0, 'Z':0}\n",
    "circuits_unadjusted = {'I':0, 'X':0, 'Y':0, 'Z':0}\n",
    "\n",
    "def rand_precision(prec_digits):\n",
    "    return Decimal(randint(0, 10**prec_digits))/10**prec_digits\n",
    "\n",
    "for i in range(samples):\n",
    "    m = 1 #m keeps track of the sign, with paulis carrying a negative sign\n",
    "    qc = QuantumCircuit(1,1)\n",
    "    op = Pauli('X')\n",
    "    for Pk in [Pauli('X'), Pauli('Y'), Pauli('Z')]:\n",
    "        #with probability 1-\\omega_k, sample the Pauli gate and compose into operator\n",
    "        if rand_precision(10) < 1-w:\n",
    "            m*=-1\n",
    "            op = op.compose(Pk) #Wow I spent so long on this silly line\n",
    "    circuits_adjusted[str(op)[-1]] += m\n",
    "    circuits_unadjusted[str(op)[-1]] += 1\n",
    "\n",
    "nums = [circuits_adjusted[i]/samples for i in circuits]\n",
    "\n",
    "print(\"sampled distribution: \", [circuits_unadjusted[i]/samples for i in circuits])\n",
    "print(\"ideal distibition :\", np.abs(probs)/np.sum(np.abs(probs)))\n",
    "print(\"simulated coefficients :\",[circuits_adjusted[i]/samples for i in circuits])\n",
    "print(\"ideal coefficients :\", probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling method vs probabilities\n",
    "\n",
    "I was seeing values that looked farther off than I expected. Here I will test how sampling from the circuit distribution aligns with knowing the probabilities before sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9855135573314567\n"
     ]
    }
   ],
   "source": [
    "mitigated = nums[1]*expec_x+nums[3]*expec_z+nums[0]*expec_i+nums[2]*expec_y\n",
    "print(mitigated*float(overhead))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9930004423842178\n"
     ]
    }
   ],
   "source": [
    "mitigated = probs[0]*expec_i+probs[1]*expec_x+probs[2]*expec_y+probs[3]*expec_z\n",
    "print(mitigated*overhead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Running these tests confirmed a few things:\n",
    "1. The error model is behaving as expected\n",
    "2. The PEC scheme works when the probabilities are known beforehand\n",
    "3. I am not sure if the sampling method is working correctly\n",
    "\n",
    "On this last point, I ran these tests because I was worried that there was an error in my method after seeing a lot of randomness in the results. Around 1000 samples, I was seeing values from `-.94` to `-1.04`. After calculating the variance, I saw that running 200000 samples should give a precision of two decimal places. However, this does not seem to be working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Calculation\n",
    "I am not great at statistics, but here is my attempt at calculating the variance of the estimator using the sampling method. Suppose a circuit is randomly samples, and the result is $\\theta$. The variance of the estimator will be\n",
    "$$\n",
    "\\langle [\\theta-\\langle \\theta \\rangle]^2 \\rangle = \\langle \\theta^2 \\rangle - \\langle \\theta \\rangle^2\n",
    "$$\n",
    " Ideal gates, when applied to $\\vert 0 \\rangle$ would get the following values of $\\langle Z \\rangle$: $(I,1),(X,-1),(Y,-1),(Z,1)$. Examining the inverse coefficients, it is apparent that $I,Y,Z$ belong to the negative volume, so the results of those measurements will be inverted: $(I,-1), (X,-1), (Y,1), (Z,-1)$. The gates are sampled from the inverse with respective probabilities $p_i, p_x, p_y, p_z$. But the gates themselves are not ideal gates, and so they suffer Pauli errors with probabilities $e_i, e_x, e_y, e_z$. The operators $X,Y$ are both bit flips, and so they flip the result, while $I,Z$ do not affect it. Therefore the probabilities of choosing $\\pm 1$ respectively are\n",
    "$$\n",
    "p_y(e_i+e_z)+(p_i+p_x+p_z)(e_y+e_x)\\\\\n",
    "p_y(e_y+e_x)+(p_i+p_x+p_z)(e_i+e_z)\n",
    "$$\n",
    "This leaves the expectation value\n",
    "$$\n",
    "p_y(e_i+e_z-e_y-e_x)+(p_i+p_x+p_z)(e_y+e_x-e_i-e_z)\n",
    "$$\n",
    "Since the result of running any circuit is either $1$ or $-1$, we have $\\langle \\theta^2 \\rangle = 1$. At the end, the result is scaled by $\\gamma$, the overhead, and so the final variance is\n",
    "$$\n",
    "\\operatorname{Var}(\\theta) = \\gamma^2\\left(1-[p_y(e_i+e_z-e_y-e_x)+(p_i+p_x+p_z)(e_y+e_x-e_i-e_z)]^2\\right)\\\\\n",
    " = \\gamma^2\\left( 1-[(p_y-p_i-p_x-p_z)(e_i+e_z-e_y-e_x)^2]\\right)\n",
    "$$\n",
    "The coefficients were calculated above to be\n",
    "$$\n",
    "\\begin{align*}\n",
    "p_x &= \\omega^3-(1-\\omega)^3\\\\\n",
    "p_i &= p_y = p_z =  \\omega(1-\\omega)(2\\omega-1)\\\\\n",
    "e_i &= \\omega^3+(1-\\omega)^3\\\\\n",
    "e_x &= e_y = e_z =  \\omega^2(1-\\omega)(2\\omega-1)\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "So the variance would be given by\n",
    "$$\n",
    "\\operatorname{Var}(\\theta) = \\gamma^2\\left( 1-[(\\omega^2(1-\\omega)(1-2\\omega)-\\omega^3+(1-\\omega)^3)(\\omega^3+(1-\\omega)^3+\\omega^2(1-\\omega)(1-2\\omega)]^2\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation:  1.5073619457746252\n"
     ]
    }
   ],
   "source": [
    "variance = overhead**2*(1-((w**2*(1-w)*(1-2*w)-w**3+(1-w)**3)*(w**3+(1-w)**3+w**2*(1-w)*(1-2*w)))**2)\n",
    "print(\"Standard deviation: \",np.sqrt(variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation of a statistical estimator will decrease as\n",
    "$$\n",
    "\\sigma_N = \\frac{\\sigma_1}{\\sqrt{N}}\n",
    "$$\n",
    "So to achieve a precision of $\\sigma_N = \\delta$, you would need\n",
    "$$\n",
    "N = \\frac{\\sigma_1^2}{\\delta^2} \\propto \\frac{\\gamma^2}{\\delta^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22721.400355694645\n"
     ]
    }
   ],
   "source": [
    "delta = .01\n",
    "print(float(variance)/delta**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
